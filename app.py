# -*- coding: utf-8 -*-
"""
ë‰´ìŠ¤ ìë™í™” ì‹œìŠ¤í…œ - ë©”ì¸ ì• í”Œë¦¬ì¼€ì´ì…˜
RSS í”¼ë“œë¥¼ í™œìš©í•œ ë‰´ìŠ¤ ìˆ˜ì§‘, ìš”ì•½ ë° PDF ë³´ê³ ì„œ ìƒì„±
"""

import streamlit as st
import feedparser
import requests
from bs4 import BeautifulSoup
from sumy.parsers.plaintext import PlaintextParser
from sumy.nlp.tokenizers import Tokenizer
from sumy.summarizers.lex_rank import LexRankSummarizer
from sumy.nlp.stemmers import Stemmer
from sumy.utils import get_stop_words
import pandas as pd
from reportlab.lib.pagesizes import A4
from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer, Table, TableStyle
from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle
from reportlab.lib.units import inch
from reportlab.lib import colors
from reportlab.pdfbase import pdfmetrics
from reportlab.pdfbase.ttfonts import TTFont
import smtplib
from email.mime.multipart import MIMEMultipart
from email.mime.text import MIMEText
from email.mime.base import MIMEBase
from email import encoders
import os
import time
import re
from datetime import datetime
import io
import nltk
from dotenv import load_dotenv
from collections import Counter

# í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# NLTK ë°ì´í„° ë‹¤ìš´ë¡œë“œ (ìµœì´ˆ ì‹¤í–‰ì‹œ)
try:
    nltk.data.find('tokenizers/punkt')
except LookupError:
    nltk.download('punkt')

class NewsCollector:
    """RSS í”¼ë“œì—ì„œ ë‰´ìŠ¤ë¥¼ ìˆ˜ì§‘í•˜ê³  í¬ë¡¤ë§í•˜ëŠ” í´ë˜ìŠ¤ (ë‹¤ì¤‘ RSS ì§€ì›)"""
    
    def __init__(self):
        self.session = requests.Session()
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
        })
        
        # ë§¤ì¼ê²½ì œ + ì—°í•©ë‰´ìŠ¤ + SBS + JTBC ë‰´ìŠ¤ RSS í”¼ë“œ ëª©ë¡
        self.rss_feeds = {
            # ë§¤ì¼ê²½ì œ RSS
            "ë§¤ê²½_í—¤ë“œë¼ì¸": "https://www.mk.co.kr/rss/30000001/",
            "ë§¤ê²½_ê²½ì œ": "https://www.mk.co.kr/rss/30100041/",
            "ë§¤ê²½_ì •ì¹˜": "https://www.mk.co.kr/rss/30200030/",
            "ë§¤ê²½_ì‚¬íšŒ": "https://www.mk.co.kr/rss/50400012/",
            "ë§¤ê²½_êµ­ì œ": "https://www.mk.co.kr/rss/30300018/",
            "ë§¤ê²½_ì¦ê¶Œ": "https://www.mk.co.kr/rss/50200011/",
            "ë§¤ê²½_ë¶€ë™ì‚°": "https://www.mk.co.kr/rss/50300009/",
            "ë§¤ê²½_ë¬¸í™”ì—°ì˜ˆ": "https://www.mk.co.kr/rss/30000023/",
            "ë§¤ê²½_ê²Œì„": "https://www.mk.co.kr/rss/50700001/",
            "ë§¤ê²½_ìŠ¤í¬ì¸ ": "https://www.mk.co.kr/rss/71000001/",
            "ë§¤ê²½_ì „ì²´": "https://www.mk.co.kr/rss/40300001/",
            
            # ì—°í•©ë‰´ìŠ¤ RSS
            "ì—°í•©ë‰´ìŠ¤_ì¢…í•©": "https://www.yna.co.kr/rss/news.xml",
            "ì—°í•©ë‰´ìŠ¤TV": "http://www.yonhapnewstv.co.kr/browse/feed/",
            "ì—°í•©ë‰´ìŠ¤TV_ë¬¸í™”": "http://www.yonhapnewstv.co.kr/category/news/culture/feed/",
            "ì—°í•©ë‰´ìŠ¤TV_êµ­ì œ": "http://www.yonhapnewstv.co.kr/category/news/international/feed/",
            "ì—°í•©ë‰´ìŠ¤TV_ì •ì¹˜": "http://www.yonhapnewstv.co.kr/category/news/politics/feed/",
            "ì—°í•©ë‰´ìŠ¤TV_ê²½ì œ": "http://www.yonhapnewstv.co.kr/category/news/economy/feed/",
            
            # SBS ë‰´ìŠ¤ RSS
            "SBS_í—¤ë“œë¼ì¸": "https://news.sbs.co.kr/news/headlineRssFeed.do?plink=RSSREADER",
            "SBS_í† í”½": "https://news.sbs.co.kr/news/TopicRssFeed.do?plink=RSSREADER",
            "SBS_ëª¨ë‹ì™€ì´ë“œ": "https://news.sbs.co.kr/news/ReplayRssFeed.do?prog_cd=R2&plink=RSSREADER",
            "SBS_8ë‰´ìŠ¤": "https://news.sbs.co.kr/news/ReplayRssFeed.do?prog_cd=RN&plink=RSSREADER",
            "SBS_SBSë‰´ìŠ¤": "https://news.sbs.co.kr/news/ReplayRssFeed.do?prog_cd=RS&plink=RSSREADER",
            
            # JTBC ë‰´ìŠ¤ RSS
            "JTBC_ë‰´ìŠ¤ë£¸": "https://news-ex.jtbc.co.kr/v1/get/rss/program/NG10000013",
            "JTBC_ì•„ì¹¨ì•¤": "https://news-ex.jtbc.co.kr/v1/get/rss/program/NG10000015",
            "JTBC_ì •ì¹˜ë¶€íšŒì˜": "https://news-ex.jtbc.co.kr/v1/get/rss/program/NG10000002"
            
        }
    
    def get_rss_feeds(self, rss_url, category_name=""):
        """RSS í”¼ë“œì—ì„œ ê¸°ì‚¬ ëª©ë¡ì„ ê°€ì ¸ì˜´"""
        try:
            feed = feedparser.parse(rss_url)
            articles = []
            
            for entry in feed.entries:
                article = {
                    'title': entry.title,
                    'link': entry.link,
                    'description': entry.get('description', ''),
                    'published': entry.get('published', ''),
                    'summary': entry.get('summary', ''),
                    'category': category_name
                }
                articles.append(article)
            
            return articles
        except Exception as e:
            st.warning(f"{category_name} RSS í”¼ë“œ ìˆ˜ì§‘ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            return []
    
    def get_all_rss_feeds(self, selected_categories=None):
        """ì„ íƒëœ ëª¨ë“  RSS í”¼ë“œì—ì„œ ê¸°ì‚¬ ëª©ë¡ì„ ê°€ì ¸ì˜´ (ê°„ë‹¨í•œ ì§„í–‰ë¥  í‘œì‹œ)"""
        if selected_categories is None:
            selected_categories = list(self.rss_feeds.keys())
        
        all_articles = []
        total_categories = len(selected_categories)
        
        # ê°„ë‹¨í•œ ì§„í–‰ë¥  í‘œì‹œ
        progress_bar = st.progress(0)
        status_text = st.empty()
        status_text.text(f"RSS í”¼ë“œ ìˆ˜ì§‘ ì¤‘... (0/{total_categories})")
        
        for i, category in enumerate(selected_categories):
            if category in self.rss_feeds:
                # ì§„í–‰ë¥  ì—…ë°ì´íŠ¸ (ì„¸ë¶€ ë‚´ìš© ì—†ì´)
                progress_bar.progress((i + 1) / total_categories)
                status_text.text(f"RSS í”¼ë“œ ìˆ˜ì§‘ ì¤‘... ({i+1}/{total_categories})")
                
                rss_url = self.rss_feeds[category]
                articles = self.get_rss_feeds(rss_url, category)
                
                if articles:
                    all_articles.extend(articles)
                
                # RSS ì„œë²„ ë¶€í•˜ ë°©ì§€
                time.sleep(0.3)  # ë”œë ˆì´ ë‹¨ì¶•
        
        # ì§„í–‰ë¥  ë°” ì œê±°
        progress_bar.empty()
        status_text.empty()
        
        # ì¤‘ë³µ ê¸°ì‚¬ ì œê±° (URL ê¸°ì¤€)
        unique_articles = []
        seen_urls = set()
        
        for article in all_articles:
            if article['link'] not in seen_urls:
                unique_articles.append(article)
                seen_urls.add(article['link'])
        
        return unique_articles
    
    def filter_by_keywords(self, articles, keywords):
        """í‚¤ì›Œë“œë¡œ ê¸°ì‚¬ í•„í„°ë§ (ê°„ë‹¨í•œ ê²°ê³¼ í‘œì‹œ)"""
        filtered_articles = []
        keywords_lower = [kw.lower() for kw in keywords]
        
        for article in articles:
            title_lower = article['title'].lower()
            desc_lower = article['description'].lower()
            
            # ì œëª©ì´ë‚˜ ì„¤ëª…ì— í‚¤ì›Œë“œê°€ í¬í•¨ëœ ê¸°ì‚¬ë§Œ ì„ íƒ
            if any(keyword in title_lower or keyword in desc_lower for keyword in keywords_lower):
                filtered_articles.append(article)
        
        return filtered_articles
    
    def crawl_article_content(self, url):
        """ê°œë³„ ê¸°ì‚¬ì˜ ë³¸ë¬¸ì„ í¬ë¡¤ë§ (ë‹¤ì¤‘ ì–¸ë¡ ì‚¬ ì§€ì›)"""
        try:
            response = self.session.get(url, timeout=10)
            response.raise_for_status()
            soup = BeautifulSoup(response.content, 'html.parser')
            
            # ì–¸ë¡ ì‚¬ë³„ ê¸°ì‚¬ ë³¸ë¬¸ ì„ íƒì
            content_selectors = []
            
            # ë§¤ì¼ê²½ì œ
            if 'mk.co.kr' in url:
                content_selectors = [
                    '.news_cnt_detail_wrap',
                    '.art_txt',
                    '.article_body',
                    '.news_content'
                ]
            
            # ì—°í•©ë‰´ìŠ¤
            elif 'yna.co.kr' in url or 'yonhapnewstv.co.kr' in url:
                content_selectors = [
                    '.story-news p',
                    '.article-text',
                    '.story-body',
                    '.news-content p'
                ]
            
            # SBS ë‰´ìŠ¤
            elif 'sbs.co.kr' in url:
                content_selectors = [
                    '.text_area',
                    '.article_content',
                    '.news_content',
                    '.article-body p'
                ]
            
            # JTBC ë‰´ìŠ¤
            elif 'jtbc.co.kr' in url:
                content_selectors = [
                    '.article_content',
                    '.news_content',
                    '.article-body',
                    '.content_text',
                    '.article_txt'
                ]
            
            # ì¼ë°˜ì ì¸ ì„ íƒì (fallback)
            content_selectors.extend([
                'div[class*="content"]',
                'div[class*="article"]',
                '.content',
                '.article',
                'article'
            ])
            
            content = ""
            for selector in content_selectors:
                elements = soup.select(selector)
                if elements:
                    content = ' '.join([elem.get_text(strip=True) for elem in elements])
                    if len(content) > 50:  # ì¶©ë¶„í•œ ë‚´ìš©ì´ ìˆì„ ë•Œë§Œ
                        break
            
            # ìµœì¢… fallback: p íƒœê·¸ì—ì„œ ë³¸ë¬¸ ì¶”ì¶œ
            if not content or len(content) < 50:
                paragraphs = soup.find_all('p')
                content = ' '.join([p.get_text(strip=True) for p in paragraphs if len(p.get_text(strip=True)) > 20])
            
            # ê´‘ê³ ë‚˜ ë¶ˆí•„ìš”í•œ í…ìŠ¤íŠ¸ ì œê±° (ê°•í™”ëœ ë²„ì „)
            if content:
                # ê¸°ì ì •ë³´, ì´ë©”ì¼, ì €ì‘ê¶Œ ë“± ì œê±°
                content = re.sub(r'[ê°€-í£]*\s*ê¸°ì.*?@.*?\.[a-z]{2,}', '', content)
                content = re.sub(r'ì €ì‘ê¶Œ.*?ê¸ˆì§€', '', content)
                content = re.sub(r'ë¬´ë‹¨.*?ê¸ˆì§€', '', content)
                content = re.sub(r'\[.*?ì•µì»¤.*?\]', '', content)
                content = re.sub(r'\[.*?ë¦¬í¬íŠ¸.*?\]', '', content)
                
                # ì•± ê´€ë ¨ ê´‘ê³  í…ìŠ¤íŠ¸ ì œê±°
                content = re.sub(r'jebo23.*?ì¹œêµ¬\s*ì¶”ê°€.*?@.*?\..*?[ê°€-í£]*', '', content)
                content = re.sub(r'ë¼ì¸\s*ì•±ì—ì„œ.*?ì¹œêµ¬\s*ì¶”ê°€', '', content)
                content = re.sub(r'ì¢‹ì•„ìš”\d+ì‘ì›í•´ìš”\d+í›„ì†\s*ì›í•´ìš”\d+', '', content)
                content = re.sub(r'ADVERTISEMENT', '', content)
                content = re.sub(r'ê´‘ê³ ', '', content)
                
                # ì‚¬ì§„/ì´ë¯¸ì§€ ì¶œì²˜ ê´€ë ¨ í…ìŠ¤íŠ¸ ì œê±°
                content = re.sub(r'ì‚¬ì§„\s*=\s*[^\n]*', '', content)
                content = re.sub(r'ì¶œì²˜\s*:\s*[^\n]*', '', content)
                content = re.sub(r'ì œê³µ\s*=\s*[^\n]*', '', content)
                content = re.sub(r'ì´ë¯¸ì§€\s*=\s*[^\n]*', '', content)
                content = re.sub(r'ì‚¬ì§„ì œê³µ\s*[^\n]*', '', content)
                content = re.sub(r'ìë£Œì‚¬ì§„\s*[^\n]*', '', content)
                content = re.sub(r'ì—°í•©ë‰´ìŠ¤\s*ìë£Œì‚¬ì§„', '', content)
                content = re.sub(r'ë‰´ì‹œìŠ¤\s*ìë£Œì‚¬ì§„', '', content)
                content = re.sub(r'ê²Œí‹°ì´ë¯¸ì§€\s*ë±…í¬', '', content)
                content = re.sub(r'AFP\s*ì—°í•©ë‰´ìŠ¤', '', content)
                content = re.sub(r'ë¡œì´í„°\s*ì—°í•©ë‰´ìŠ¤', '', content)
                
                # ì†Œì…œë¯¸ë””ì–´ ê´€ë ¨ í…ìŠ¤íŠ¸ ì œê±°
                content = re.sub(r'í˜ì´ìŠ¤ë¶.*?ê³µìœ ', '', content)
                content = re.sub(r'íŠ¸ìœ„í„°.*?ê³µìœ ', '', content)
                content = re.sub(r'ì¹´ì¹´ì˜¤í†¡.*?ê³µìœ ', '', content)
                content = re.sub(r'ë„¤ì´ë²„.*?ê³µìœ ', '', content)
                
                # êµ¬ë…/ì•Œë¦¼ ê´€ë ¨ í…ìŠ¤íŠ¸ ì œê±°
                content = re.sub(r'êµ¬ë….*?ì•Œë¦¼', '', content)
                content = re.sub(r'íŒ”ë¡œìš°.*?í•˜ê¸°', '', content)
                content = re.sub(r'ë”\s*ë§ì€.*?ë‰´ìŠ¤', '', content)
                
                # ì›¹ì‚¬ì´íŠ¸ UI ë° ì œë³´ ê´€ë ¨ í…ìŠ¤íŠ¸ ì œê±°
                content = re.sub(r'ë‹«ê¸°', '', content)
                content = re.sub(r'ì œë³´ëŠ”.*?ì¹´ì¹´ì˜¤í†¡', '', content)
                content = re.sub(r'ì œë³´.*?ì ‘ìˆ˜', '', content)
                content = re.sub(r'ë‰´ìŠ¤\s*ì œë³´', '', content)
                content = re.sub(r'ë…ì\s*ì œë³´', '', content)
                content = re.sub(r'ì‹œì²­ì\s*ì œë³´', '', content)
                content = re.sub(r'ì·¨ì¬\s*ìš”ì²­', '', content)
                content = re.sub(r'ë¬¸ì˜.*?ì—°ë½ì²˜', '', content)
                content = re.sub(r'í™ˆí˜ì´ì§€.*?ë°”ë¡œê°€ê¸°', '', content)
                content = re.sub(r'ëª¨ë°”ì¼.*?ë²„ì „', '', content)
                content = re.sub(r'PC.*?ë²„ì „', '', content)
                content = re.sub(r'ì „ì²´.*?ë©”ë‰´', '', content)
                content = re.sub(r'ë©”ë‰´.*?ë‹«ê¸°', '', content)
                content = re.sub(r'ë¡œê·¸ì¸.*?íšŒì›ê°€ì…', '', content)
                content = re.sub(r'íšŒì›.*?ì„œë¹„ìŠ¤', '', content)
                
                # ì—°ì†ëœ ê³µë°± ì •ë¦¬
                content = re.sub(r'\s+', ' ', content)
                content = content.strip()
                
            return content[:2500] if content else "ë³¸ë¬¸ì„ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
            
        except Exception as e:
            return f"í¬ë¡¤ë§ ì˜¤ë¥˜: {str(e)}"
    
    def collect_news_with_content(self, keywords):
        """í‚¤ì›Œë“œ ê¸°ë°˜ìœ¼ë¡œ ëª¨ë“  RSSì—ì„œ ë‰´ìŠ¤ë¥¼ ìë™ ìˆ˜ì§‘í•˜ê³  ë³¸ë¬¸ê¹Œì§€ í¬ë¡¤ë§"""
        
        # 1ë‹¨ê³„: ëª¨ë“  RSSì—ì„œ ê¸°ì‚¬ ëª©ë¡ ê°€ì ¸ì˜¤ê¸° (ìë™ìœ¼ë¡œ ì „ì²´ ìˆ˜ì§‘)
        st.info("ğŸ”„ 1ë‹¨ê³„: ëª¨ë“  RSS í”¼ë“œì—ì„œ ê¸°ì‚¬ ëª©ë¡ ìˆ˜ì§‘ ì¤‘...")
        all_articles = self.get_all_rss_feeds(list(self.rss_feeds.keys()))  # ëª¨ë“  ì¹´í…Œê³ ë¦¬ ìë™ ìˆ˜ì§‘
        
        if not all_articles:
            return []
        
        # 2ë‹¨ê³„: í‚¤ì›Œë“œë¡œ í•„í„°ë§
        st.info("ğŸ” 2ë‹¨ê³„: í‚¤ì›Œë“œ ë§¤ì¹­ ì¤‘...")
        filtered_articles = self.filter_by_keywords(all_articles, keywords)
        
        if not filtered_articles:
            st.warning("ğŸ˜… í‚¤ì›Œë“œì™€ ë§¤ì¹­ë˜ëŠ” ê¸°ì‚¬ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return []
        
        # 3ë‹¨ê³„: ê° ê¸°ì‚¬ì˜ ë³¸ë¬¸ í¬ë¡¤ë§
        st.info(f"ğŸ“° 3ë‹¨ê³„: {len(filtered_articles)}ê°œ ê¸°ì‚¬ ë³¸ë¬¸ í¬ë¡¤ë§ ì¤‘...")
        
        # ì§„í–‰ìƒí™© í‘œì‹œ
        progress_bar = st.progress(0)
        status_text = st.empty()
        
        for i, article in enumerate(filtered_articles):
            status_text.text(f'ê¸°ì‚¬ í¬ë¡¤ë§ ì¤‘... {i+1}/{len(filtered_articles)} - {article["category"]}')
            progress_bar.progress((i + 1) / len(filtered_articles))
            
            content = self.crawl_article_content(article['link'])
            article['content'] = content
            
            # ì„œë²„ ë¶€í•˜ ë°©ì§€ë¥¼ ìœ„í•œ ë”œë ˆì´
            time.sleep(1)
        
        progress_bar.empty()
        status_text.empty()
        
        return filtered_articles

class TextProcessor:
    """í…ìŠ¤íŠ¸ ìš”ì•½ ë° í‚¤ì›Œë“œ ì¶”ì¶œ í´ë˜ìŠ¤ (ê°œì„ ëœ ë²„ì „)"""
    
    def __init__(self, language='korean'):
        self.language = language
        try:
            from sumy.nlp.stemmers import Stemmer
            from sumy.summarizers.lex_rank import LexRankSummarizer
            from sumy.utils import get_stop_words
            
            self.stemmer = Stemmer(language)
            self.summarizer = LexRankSummarizer(self.stemmer)
            self.summarizer.stop_words = get_stop_words(language)
            self.use_sumy = True
        except Exception as e:
            st.warning(f"Sumy ì´ˆê¸°í™” ì‹¤íŒ¨: {str(e)}. ê°„ë‹¨í•œ ìš”ì•½ ë°©ì‹ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.")
            self.use_sumy = False
    
    def simple_summarize(self, text, max_sentences=3):
        """í•œêµ­ì–´ ìµœì í™”ëœ ê°„ë‹¨í•œ ë¬¸ì¥ ê¸°ë°˜ ìš”ì•½"""
        if not text or len(text.strip()) < 50:
            return "ìš”ì•½í•  ë‚´ìš©ì´ ë¶€ì¡±í•©ë‹ˆë‹¤."
        
        # í•œêµ­ì–´ ë¬¸ì¥ ë¶„ë¦¬ (ë” ì •í™•í•œ ë°©ë²•)
        sentences = []
        # í•œêµ­ì–´ ë¬¸ì¥ ë í‘œì‹œ: ., !, ?, ë‹¤, ì—ˆë‹¤, ì˜€ë‹¤, ã…‚ë‹ˆë‹¤, ìŠµë‹ˆë‹¤ ë“±
        sentence_endings = re.split(r'[.!?]|ë‹¤\s|ì—ˆë‹¤\s|ì˜€ë‹¤\s|ìŠµë‹ˆë‹¤\s|ã…‚ë‹ˆë‹¤\s', text)
        
        for sentence in sentence_endings:
            sentence = sentence.strip()
            # ë„ˆë¬´ ì§§ì€ ë¬¸ì¥, ê¸°ì ì„œëª…, ì‚¬ì§„ ì¶œì²˜, UI ê´€ë ¨ ë¬¸ì¥ ì œì™¸
            if (len(sentence) > 15 and 
                'ê¸°ì' not in sentence[:10] and
                'ì‚¬ì§„=' not in sentence and
                'ì¶œì²˜:' not in sentence and
                'ì œê³µ=' not in sentence and
                'ì´ë¯¸ì§€=' not in sentence and
                'ìë£Œì‚¬ì§„' not in sentence and
                'ê²Œí‹°ì´ë¯¸ì§€' not in sentence and
                'AFP' not in sentence and
                'ë¡œì´í„°' not in sentence and
                'ë‹«ê¸°' not in sentence and
                'ì œë³´ëŠ”' not in sentence and
                'ì¹´ì¹´ì˜¤í†¡' not in sentence and
                'ë‰´ìŠ¤ì œë³´' not in sentence and
                'ë…ìì œë³´' not in sentence and
                'ì‹œì²­ìì œë³´' not in sentence and
                'ì·¨ì¬ìš”ì²­' not in sentence and
                'í™ˆí˜ì´ì§€' not in sentence and
                'ë°”ë¡œê°€ê¸°' not in sentence and
                'ë¡œê·¸ì¸' not in sentence and
                'íšŒì›ê°€ì…' not in sentence and
                '.kr' not in sentence and
                '.com' not in sentence):
                sentences.append(sentence)
        
        if len(sentences) == 0:
            # fallback: ë§ˆì¹¨í‘œë¡œë§Œ ë¶„ë¦¬
            sentences = [s.strip() for s in text.split('.') if len(s.strip()) > 15]
        
        if len(sentences) == 0:
            return "ë¬¸ì¥ì„ ë¶„ë¦¬í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        
        # í•œêµ­ì–´ ë‹¨ì–´ ë¹ˆë„ ê³„ì‚° (ê°œì„ ëœ ë²„ì „)
        word_freq = {}
        all_text = ' '.join(sentences)
        
        # í•œêµ­ì–´ ë‹¨ì–´ ì¶”ì¶œ (2ê¸€ì ì´ìƒ)
        korean_words = re.findall(r'[ê°€-í£]{2,}', all_text)
        english_words = re.findall(r'[a-zA-Z]{3,}', all_text)
        numbers = re.findall(r'\d+', all_text)
        
        all_words = korean_words + english_words + numbers
        
        # ë¶ˆìš©ì–´ í™•ì¥ (ì•±/ê´‘ê³  ê´€ë ¨ ë‹¨ì–´ ì¶”ê°€)
        stop_words = {
            'ì´ê²ƒ', 'ê·¸ê²ƒ', 'ì €ê²ƒ', 'ì´ëŸ°', 'ê·¸ëŸ°', 'ì €ëŸ°', 'ì´ë ‡ê²Œ', 'ê·¸ë ‡ê²Œ', 'ì €ë ‡ê²Œ',
            'ë•Œë¬¸', 'ê²½ìš°', 'ë•Œë¬¸ì—', 'í•˜ì§€ë§Œ', 'ê·¸ëŸ¬ë‚˜', 'ê·¸ëŸ°ë°', 'ë˜í•œ', 'ê·¸ë¦¬ê³ ',
            'ì´ë‹¤', 'ìˆë‹¤', 'ì—†ë‹¤', 'í•œë‹¤', 'ëœë‹¤', 'ì´ë©°', 'ì´ê³ ', 'ì—ì„œ', 'ì—ê²Œ',
            'ê¸°ì', 'ë‰´ìŠ¤', 'ê¸°ì‚¬', 'ë³´ë„', 'ë°œí‘œ', 'ê´€ë ¨', 'ëŒ€í•´', 'í•œêµ­', 'ìš°ë¦¬ë‚˜ë¼',
            'ì˜¤ëŠ˜', 'ì–´ì œ', 'ë‚´ì¼', 'ì˜¬í•´', 'ì§€ë‚œí•´', 'ì˜¬í•´', 'ë‚´ë…„', 'ì§€ë‚œ', 'ë‹¤ìŒ',
            'í˜„ì¬', 'ìµœê·¼', 'ì•ìœ¼ë¡œ', 'í–¥í›„', 'ì´í›„', 'ì´ì „', 'ë‹¹ì‹œ', 'ì§€ê¸ˆ',
            # ì•±/ê´‘ê³  ê´€ë ¨ ë¶ˆìš©ì–´ ì¶”ê°€
            'jebo23', 'ë¼ì¸', 'ì•±ì—ì„œ', 'ì¹œêµ¬', 'ì¶”ê°€', 'ì¢‹ì•„ìš”', 'ì‘ì›í•´ìš”', 'í›„ì†', 'ì›í•´ìš”',
            'ADVERTISEMENT', 'ê´‘ê³ ', 'AD', 'ê³µìœ ', 'ê³µìœ í•˜ê¸°', 'êµ¬ë…', 'ì•Œë¦¼', 'íŒ”ë¡œìš°',
            'ë‹¤ìš´ë¡œë“œ', 'ëª¨ë°”ì¼', 'í˜ì´ìŠ¤ë¶', 'íŠ¸ìœ„í„°', 'ì¹´ì¹´ì˜¤í†¡', 'ë„¤ì´ë²„', 'ë”ë³´ê¸°',
            'yna', 'krc', 'co', 'kr'
        }
        
        for word in all_words:
            if len(word) >= 2 and word not in stop_words:
                word_freq[word] = word_freq.get(word, 0) + 1
        
        # ë¬¸ì¥ë³„ ì¤‘ìš”ë„ ì ìˆ˜ ê³„ì‚°
        sentence_scores = {}
        for sentence in sentences:
            # ë¬¸ì¥ì—ì„œ ë‹¨ì–´ ì¶”ì¶œ
            sentence_korean = re.findall(r'[ê°€-í£]{2,}', sentence)
            sentence_english = re.findall(r'[a-zA-Z]{3,}', sentence)
            sentence_numbers = re.findall(r'\d+', sentence)
            sentence_words = sentence_korean + sentence_english + sentence_numbers
            
            # ê¸°ë³¸ ì ìˆ˜ ê³„ì‚°
            score = sum(word_freq.get(word, 0) for word in sentence_words)
            
            # ë¬¸ì¥ ìœ„ì¹˜ ë³´ì • (ì•ìª½ ë¬¸ì¥ì— ë” ë†’ì€ ì ìˆ˜)
            position_weight = 1.0
            sentence_index = sentences.index(sentence)
            if sentence_index < len(sentences) * 0.3:  # ì•ìª½ 30%
                position_weight = 1.3
            elif sentence_index > len(sentences) * 0.7:  # ë’¤ìª½ 30%
                position_weight = 0.8
            
            # ë¬¸ì¥ ê¸¸ì´ ë³´ì •
            length_weight = 1.0
            if 30 <= len(sentence) <= 150:  # ì ì ˆí•œ ê¸¸ì´
                length_weight = 1.2
            elif len(sentence) < 20 or len(sentence) > 200:  # ë„ˆë¬´ ì§§ê±°ë‚˜ ê¹€
                length_weight = 0.7
            
            sentence_scores[sentence] = score * position_weight * length_weight
        
        # ìƒìœ„ ë¬¸ì¥ë“¤ ì„ íƒ
        if len(sentence_scores) == 0:
            return "ì ìˆ˜ë¥¼ ê³„ì‚°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        
        top_sentences = sorted(sentence_scores.items(), key=lambda x: x[1], reverse=True)
        summary_sentences = [sentence for sentence, score in top_sentences[:max_sentences]]
        
        # ì›ë˜ ìˆœì„œëŒ€ë¡œ ì •ë ¬ (ì‹œê°„ ìˆœì„œ ìœ ì§€)
        final_sentences = []
        for sentence in sentences:
            if sentence in summary_sentences:
                final_sentences.append(sentence)
                if len(final_sentences) >= max_sentences:
                    break
        
        result = '. '.join(final_sentences)
        if not result.endswith('.'):
            result += '.'
        
        return result if result != '.' else "ìš”ì•½ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
    
    def summarize_text(self, text, sentences_count=3):
        """í•œêµ­ì–´ ìµœì í™”ëœ í…ìŠ¤íŠ¸ ìš”ì•½"""
        try:
            if not text or len(text.strip()) < 50:
                return "ìš”ì•½í•  ë‚´ìš©ì´ ë¶€ì¡±í•©ë‹ˆë‹¤."
            
            # í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬ (í•œêµ­ì–´ ìµœì í™”)
            text = re.sub(r'\s+', ' ', text)  # ì—¬ëŸ¬ ê³µë°±ì„ í•˜ë‚˜ë¡œ
            text = text.strip()
            
            # ê¸°ì ì •ë³´, ì´ë©”ì¼, URL ë“± ì œê±° (ê°•í™”ëœ ë²„ì „)
            text = re.sub(r'[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}', '', text)  # ì´ë©”ì¼ ì œê±°
            text = re.sub(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', '', text)  # URL ì œê±°
            text = re.sub(r'[ê°€-í£]+\s*ê¸°ì', '', text)  # ê¸°ì ì´ë¦„ ì œê±°
            text = re.sub(r'ã€.*?ã€‘', '', text)  # ã€ã€‘ ê´„í˜¸ ë‚´ìš© ì œê±°
            text = re.sub(r'\[.*?\]', '', text)  # [] ê´„í˜¸ ë‚´ìš© ì œê±°
            
            # ì•± ë° ê´‘ê³  ê´€ë ¨ í…ìŠ¤íŠ¸ ì œê±° (ìš”ì•½ ì „ì²˜ë¦¬)
            text = re.sub(r'jebo23.*?ì¹œêµ¬\s*ì¶”ê°€.*?@.*?\..*?[ê°€-í£]*', '', text)
            text = re.sub(r'ë¼ì¸\s*ì•±ì—ì„œ.*?ì¹œêµ¬\s*ì¶”ê°€', '', text)
            text = re.sub(r'ì¢‹ì•„ìš”\d+ì‘ì›í•´ìš”\d+í›„ì†\s*ì›í•´ìš”\d+', '', text)
            text = re.sub(r'ADVERTISEMENT', '', text)
            text = re.sub(r'ê´‘ê³ ', '', text)
            text = re.sub(r'AD', '', text)
            
            # ì†Œì…œë¯¸ë””ì–´ ë° ê³µìœ  ê´€ë ¨ í…ìŠ¤íŠ¸ ì œê±°
            text = re.sub(r'í˜ì´ìŠ¤ë¶.*?ê³µìœ ', '', text)
            text = re.sub(r'íŠ¸ìœ„í„°.*?ê³µìœ ', '', text)
            text = re.sub(r'ì¹´ì¹´ì˜¤í†¡.*?ê³µìœ ', '', text)
            text = re.sub(r'ë„¤ì´ë²„.*?ê³µìœ ', '', text)
            text = re.sub(r'ê³µìœ í•˜ê¸°', '', text)
            
            # êµ¬ë…/ì•Œë¦¼/íŒ”ë¡œìš° ê´€ë ¨ í…ìŠ¤íŠ¸ ì œê±°
            text = re.sub(r'êµ¬ë….*?ì•Œë¦¼', '', text)
            text = re.sub(r'íŒ”ë¡œìš°.*?í•˜ê¸°', '', text)
            text = re.sub(r'ë”\s*ë§ì€.*?ë‰´ìŠ¤', '', text)
            text = re.sub(r'ë‰´ìŠ¤\s*ë”ë³´ê¸°', '', text)
            
            # ì•± ë‹¤ìš´ë¡œë“œ ê´€ë ¨ í…ìŠ¤íŠ¸ ì œê±°
            text = re.sub(r'ì•±\s*ë‹¤ìš´ë¡œë“œ', '', text)
            text = re.sub(r'ëª¨ë°”ì¼.*?ì•±', '', text)
            
            # ì‚¬ì§„/ì´ë¯¸ì§€ ì¶œì²˜ ê´€ë ¨ í…ìŠ¤íŠ¸ ì œê±° (ìš”ì•½ ì „ì²˜ë¦¬)
            text = re.sub(r'ì‚¬ì§„\s*=\s*[^\n.]*', '', text)
            text = re.sub(r'ì¶œì²˜\s*:\s*[^\n.]*', '', text)
            text = re.sub(r'ì œê³µ\s*=\s*[^\n.]*', '', text)
            text = re.sub(r'ì´ë¯¸ì§€\s*=\s*[^\n.]*', '', text)
            text = re.sub(r'ì‚¬ì§„ì œê³µ\s*[^\n.]*', '', text)
            text = re.sub(r'ìë£Œì‚¬ì§„\s*[^\n.]*', '', text)
            text = re.sub(r'ì—°í•©ë‰´ìŠ¤\s*ìë£Œì‚¬ì§„', '', text)
            text = re.sub(r'ë‰´ì‹œìŠ¤\s*ìë£Œì‚¬ì§„', '', text)
            text = re.sub(r'ê²Œí‹°ì´ë¯¸ì§€\s*ë±…í¬', '', text)
            text = re.sub(r'AFP\s*ì—°í•©ë‰´ìŠ¤', '', text)
            text = re.sub(r'ë¡œì´í„°\s*ì—°í•©ë‰´ìŠ¤', '', text)
            text = re.sub(r'EPA\s*ì—°í•©ë‰´ìŠ¤', '', text)
            text = re.sub(r'AP\s*ì—°í•©ë‰´ìŠ¤', '', text)
            text = re.sub(r'ì‚¬ì§„\s*ì¶œì²˜', '', text)
            text = re.sub(r'ì´ë¯¸ì§€\s*ì¶œì²˜', '', text)
            
            # ì›¹ì‚¬ì´íŠ¸ UI ë° ì œë³´ ê´€ë ¨ í…ìŠ¤íŠ¸ ì œê±° (ìš”ì•½ ì „ì²˜ë¦¬)
            text = re.sub(r'ë‹«ê¸°', '', text)
            text = re.sub(r'ì œë³´ëŠ”.*?ì¹´ì¹´ì˜¤í†¡', '', text)
            text = re.sub(r'ì œë³´.*?ì ‘ìˆ˜', '', text)
            text = re.sub(r'ë‰´ìŠ¤\s*ì œë³´', '', text)
            text = re.sub(r'ë…ì\s*ì œë³´', '', text)
            text = re.sub(r'ì‹œì²­ì\s*ì œë³´', '', text)
            text = re.sub(r'ì·¨ì¬\s*ìš”ì²­', '', text)
            text = re.sub(r'ë¬¸ì˜.*?ì—°ë½ì²˜', '', text)
            text = re.sub(r'í™ˆí˜ì´ì§€.*?ë°”ë¡œê°€ê¸°', '', text)
            text = re.sub(r'ëª¨ë°”ì¼.*?ë²„ì „', '', text)
            text = re.sub(r'PC.*?ë²„ì „', '', text)
            text = re.sub(r'ì „ì²´.*?ë©”ë‰´', '', text)
            text = re.sub(r'ë©”ë‰´.*?ë‹«ê¸°', '', text)
            text = re.sub(r'ë¡œê·¸ì¸.*?íšŒì›ê°€ì…', '', text)
            text = re.sub(r'íšŒì›.*?ì„œë¹„ìŠ¤', '', text)
            text = re.sub(r'ì´ìš©ì•½ê´€.*?ê°œì¸ì •ë³´', '', text)
            text = re.sub(r'ê°œì¸ì •ë³´.*?ì²˜ë¦¬ë°©ì¹¨', '', text)
            text = re.sub(r'ì €ì‘ê¶Œ.*?ì •ì±…', '', text)
            text = re.sub(r'ì²­ì†Œë…„.*?ë³´í˜¸ì •ì±…', '', text)
            
            # ë„ë©”ì¸ ë° ê¸°ìˆ ì  í…ìŠ¤íŠ¸ ì œê±°
            text = re.sub(r'\.kr\b', '', text)
            text = re.sub(r'\.co\.kr\b', '', text)
            text = re.sub(r'\.com\b', '', text)
            text = re.sub(r'www\.', '', text)
            text = re.sub(r'http[s]?://', '', text)
            
            # ì—°ì†ëœ ê³µë°±ê³¼ íŠ¹ìˆ˜ë¬¸ì ì •ë¦¬
            text = re.sub(r'\s+', ' ', text)
            text = re.sub(r'[^\w\sê°€-í£.,!?]', ' ', text)  # íŠ¹ìˆ˜ë¬¸ì ì œê±° (í•œê¸€, ì˜ë¬¸, ìˆ«ì, ê¸°ë³¸ ë¬¸ì¥ë¶€í˜¸ë§Œ ìœ ì§€)
            text = text.strip()
            
            # Sumy ì‹œë„ (í•œêµ­ì–´ ì„¤ì • ê°œì„ )
            if self.use_sumy:
                try:
                    from sumy.parsers.plaintext import PlaintextParser
                    from sumy.nlp.tokenizers import Tokenizer
                    
                    # í•œêµ­ì–´ í† í¬ë‚˜ì´ì € ëª…ì‹œì  ì„¤ì •
                    parser = PlaintextParser.from_string(text, Tokenizer('korean'))
                    summary_sentences = self.summarizer(parser.document, sentences_count)
                    
                    summary = ' '.join([str(sentence).strip() for sentence in summary_sentences])
                    
                    # Sumy ê²°ê³¼ ê²€ì¦
                    if summary and len(summary.strip()) > 20 and 'ìš”ì•½' not in summary:
                        return summary.strip()
                    else:
                        return self.simple_summarize(text, sentences_count)
                        
                except Exception as e:
                    # Sumy ì‹¤íŒ¨ ì‹œ ìì²´ ìš”ì•½ ì‚¬ìš©
                    return self.simple_summarize(text, sentences_count)
            else:
                return self.simple_summarize(text, sentences_count)
                
        except Exception as e:
            return f"ìš”ì•½ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"
    
    def extract_keywords(self, text, top_k=5):
        """ê°„ë‹¨í•œ í‚¤ì›Œë“œ ì¶”ì¶œ (ê°œì„ ëœ ë²„ì „)"""
        try:
            if not text:
                return []
            
            # í•œê¸€, ì˜ë¬¸, ìˆ«ìë§Œ ì¶”ì¶œ
            words = re.findall(r'[ê°€-í£a-zA-Z0-9]+', text)
            
            # ë¶ˆìš©ì–´ ì œê±° (ì•±/ê´‘ê³  ê´€ë ¨ ë‹¨ì–´ ì¶”ê°€)
            stop_words = {
                'ì´', 'ê·¸', 'ì €', 'ê²ƒ', 'ìˆ˜', 'ë“±', 'ë°', 'ì˜', 'ë¥¼', 'ì„', 'ê°€', 'ì´', 'ì€', 'ëŠ”', 
                'ì—', 'ì—ì„œ', 'ìœ¼ë¡œ', 'ë¡œ', 'ì™€', 'ê³¼', 'í•˜ê³ ', 'ê·¸ë¦¬ê³ ', 'ë˜ëŠ”', 'í•˜ì§€ë§Œ', 
                'ê·¸ëŸ¬ë‚˜', 'ë”°ë¼ì„œ', 'ìœ„í•´', 'í†µí•´', 'ëŒ€í•œ', 'ìœ„í•œ', 'ìˆëŠ”', 'ì—†ëŠ”', 'ìˆë‹¤', 
                'ì—†ë‹¤', 'ì´ë‹¤', 'ì•„ë‹ˆë‹¤', 'í•œë‹¤', 'ëœë‹¤', 'ê²ƒì´', 'ê²ƒì€', 'ê²ƒì„',
                'ê¸°ì', 'ë‰´ìŠ¤', 'ê¸°ì‚¬', 'ë³´ë„', 'ë°œí‘œ', 'ê´€ë ¨', 'ëŒ€í•´', 'ì—ì„œ', 'í•œêµ­',
                'ì˜¤ëŠ˜', 'ì–´ì œ', 'ë‚´ì¼', 'ì˜¬í•´', 'ì§€ë‚œ', 'ì•ìœ¼ë¡œ',
                # ì•±/ê´‘ê³  ê´€ë ¨ ë¶ˆìš©ì–´ ì¶”ê°€
                'jebo23', 'ë¼ì¸', 'ì•±ì—ì„œ', 'ì¹œêµ¬', 'ì¶”ê°€', 'ì¢‹ì•„ìš”', 'ì‘ì›í•´ìš”', 'í›„ì†', 'ì›í•´ìš”',
                'ADVERTISEMENT', 'ê´‘ê³ ', 'AD', 'ê³µìœ ', 'ê³µìœ í•˜ê¸°', 'êµ¬ë…', 'ì•Œë¦¼', 'íŒ”ë¡œìš°',
                'ë‹¤ìš´ë¡œë“œ', 'ëª¨ë°”ì¼', 'í˜ì´ìŠ¤ë¶', 'íŠ¸ìœ„í„°', 'ì¹´ì¹´ì˜¤í†¡', 'ë„¤ì´ë²„', 'ë”ë³´ê¸°',
                'yna', 'krc', 'co', 'kr', 'ë¬¸í™”', 'ì—°ì˜ˆ',
                # ì‚¬ì§„/ì´ë¯¸ì§€ ì¶œì²˜ ê´€ë ¨ ë¶ˆìš©ì–´ ì¶”ê°€
                'ì‚¬ì§„', 'ì¶œì²˜', 'ì œê³µ', 'ì´ë¯¸ì§€', 'ìë£Œì‚¬ì§„', 'ì‚¬ì§„ì œê³µ', 'ì´ë¯¸ì§€ì¶œì²˜', 'ì‚¬ì§„ì¶œì²˜',
                'ê²Œí‹°ì´ë¯¸ì§€', 'ë±…í¬', 'AFP', 'ë¡œì´í„°', 'ë‰´ì‹œìŠ¤', 'EPA', 'AP',
                # ì›¹ì‚¬ì´íŠ¸ UI ë° ì œë³´ ê´€ë ¨ ë¶ˆìš©ì–´ ì¶”ê°€
                'ë‹«ê¸°', 'ì œë³´ëŠ”', 'ì œë³´', 'ë‰´ìŠ¤ì œë³´', 'ë…ìì œë³´', 'ì‹œì²­ìì œë³´', 'ì·¨ì¬ìš”ì²­', 'ì·¨ì¬',
                'í™ˆí˜ì´ì§€', 'ë°”ë¡œê°€ê¸°', 'ë¡œê·¸ì¸', 'íšŒì›ê°€ì…', 'íšŒì›', 'ì„œë¹„ìŠ¤', 'ì´ìš©ì•½ê´€',
                'ê°œì¸ì •ë³´', 'ì²˜ë¦¬ë°©ì¹¨', 'ì €ì‘ê¶Œ', 'ì •ì±…', 'ì²­ì†Œë…„', 'ë³´í˜¸ì •ì±…', 'ë©”ë‰´', 'ì „ì²´',
                'www', 'http', 'https', 'com', 'ë²„ì „', 'PC', 'ëª¨ë°”ì¼', 'ë¬¸ì˜', 'ì—°ë½ì²˜', 'ì ‘ìˆ˜'
            }
            
            # ë‹¨ì–´ ë¹ˆë„ ê³„ì‚°
            word_freq = {}
            for word in words:
                if len(word) >= 2 and word not in stop_words:
                    word_freq[word] = word_freq.get(word, 0) + 1
            
            # ë‹¨ì–´ ê¸¸ì´ ê°€ì¤‘ì¹˜ ì ìš©
            for word in word_freq:
                if len(word) >= 4:
                    word_freq[word] *= 1.5
            
            # ë¹ˆë„ìˆœìœ¼ë¡œ ì •ë ¬í•˜ì—¬ ìƒìœ„ í‚¤ì›Œë“œ ë°˜í™˜
            keywords = sorted(word_freq.items(), key=lambda x: x[1], reverse=True)[:top_k]
            return [word for word, freq in keywords if freq >= 2]
            
        except Exception as e:
            return []

class PDFGenerator:
    """PDF ë³´ê³ ì„œ ìƒì„± í´ë˜ìŠ¤ - ì‚¬ìš©ì ì¹œí™”ì  ë””ìì¸"""
    
    def __init__(self):
        # í•œê¸€ í°íŠ¸ ë“±ë¡
        try:
            pdfmetrics.registerFont(TTFont('korean', 'C:/Windows/Fonts/malgun.ttf'))
            pdfmetrics.registerFont(TTFont('korean-bold', 'C:/Windows/Fonts/malgunbd.ttf'))
        except:
            try:
                pdfmetrics.registerFont(TTFont('korean', '/System/Library/Fonts/AppleGothic.ttf'))
                pdfmetrics.registerFont(TTFont('korean-bold', '/System/Library/Fonts/AppleGothic.ttf'))
            except:
                try:
                    pdfmetrics.registerFont(TTFont('korean', '/usr/share/fonts/truetype/noto/NotoSansCJK-Regular.ttc'))
                    pdfmetrics.registerFont(TTFont('korean-bold', '/usr/share/fonts/truetype/noto/NotoSansCJK-Bold.ttc'))
                except:
                    pass
        
        self.setup_styles()
    
    def setup_styles(self):
        """ëª¨ë˜í•˜ê³  ì‚¬ìš©ì ì¹œí™”ì ì¸ ìŠ¤íƒ€ì¼ ì„¤ì •"""
        self.styles = getSampleStyleSheet()
        
        # í°íŠ¸ ì„¤ì •
        try:
            font_name = 'korean'
            bold_font = 'korean-bold'
        except:
            font_name = 'Helvetica'
            bold_font = 'Helvetica-Bold'
        
        # ìƒ‰ìƒ ì •ì˜
        self.colors = {
            'primary': colors.Color(0.2, 0.4, 0.8),      # ì§„í•œ íŒŒë€ìƒ‰
            'secondary': colors.Color(0.1, 0.7, 0.9),    # í•˜ëŠ˜ìƒ‰
            'accent': colors.Color(0.9, 0.6, 0.1),       # ì£¼í™©ìƒ‰
            'success': colors.Color(0.2, 0.7, 0.3),      # ì´ˆë¡ìƒ‰
            'text': colors.Color(0.2, 0.2, 0.2),         # ì§„í•œ íšŒìƒ‰
            'light_bg': colors.Color(0.97, 0.98, 1.0),   # ì—°í•œ íŒŒë€ ë°°ê²½
            'header_bg': colors.Color(0.1, 0.3, 0.6),    # í—¤ë” ë°°ê²½
            'border': colors.Color(0.8, 0.8, 0.8),       # í…Œë‘ë¦¬ ìƒ‰ìƒ
        }
        
        # ìŠ¤íƒ€ì¼ ì´ë¦„ ëª©ë¡ (ì¤‘ë³µ ë°©ì§€ìš©)
        style_names = [
            'MainTitle', 'SectionTitle', 'ArticleTitle', 
            'BodyText', 'MetaInfo', 'Summary', 'Keywords'
        ]
        
        # ê¸°ì¡´ ì»¤ìŠ¤í…€ ìŠ¤íƒ€ì¼ ì œê±° (ì¤‘ë³µ ë°©ì§€)
        for style_name in style_names:
            if style_name in self.styles.byName:
                del self.styles.byName[style_name]
        
        # ë©”ì¸ ì œëª© ìŠ¤íƒ€ì¼
        self.styles.add(ParagraphStyle(
            name='MainTitle',
            parent=self.styles['Title'],
            fontName=bold_font,
            fontSize=24,
            textColor=self.colors['primary'],
            spaceAfter=30,
            alignment=1,  # ê°€ìš´ë° ì •ë ¬
            borderWidth=2,
            borderColor=self.colors['primary'],
            borderPadding=15,
            backColor=self.colors['light_bg'],
        ))
        
        # ì„¹ì…˜ ì œëª© ìŠ¤íƒ€ì¼
        self.styles.add(ParagraphStyle(
            name='SectionTitle',
            parent=self.styles['Heading2'],
            fontName=bold_font,
            fontSize=16,
            textColor=colors.white,
            backColor=self.colors['header_bg'],
            spaceBefore=20,
            spaceAfter=15,
            leftIndent=15,
            rightIndent=15,
            borderPadding=10,
            alignment=0,
        ))
        
        # ê¸°ì‚¬ ì œëª© ìŠ¤íƒ€ì¼
        self.styles.add(ParagraphStyle(
            name='ArticleTitle',
            parent=self.styles['Heading3'],
            fontName=bold_font,
            fontSize=14,
            textColor=self.colors['primary'],
            spaceBefore=15,
            spaceAfter=10,
            leftIndent=5,
            backColor=colors.Color(0.95, 0.97, 1.0),
            borderPadding=8,
        ))
        
        # ë³¸ë¬¸ ìŠ¤íƒ€ì¼
        self.styles.add(ParagraphStyle(
            name='BodyText',
            parent=self.styles['Normal'],
            fontName=font_name,
            fontSize=11,
            textColor=self.colors['text'],
            spaceAfter=8,
            leading=16,
            leftIndent=10,
            rightIndent=10,
        ))
        
        # ë©”íƒ€ ì •ë³´ ìŠ¤íƒ€ì¼
        self.styles.add(ParagraphStyle(
            name='MetaInfo',
            parent=self.styles['Normal'],
            fontName=font_name,
            fontSize=10,
            textColor=colors.Color(0.4, 0.4, 0.4),
            spaceAfter=6,
            leftIndent=10,
        ))
        
        # ìš”ì•½ ìŠ¤íƒ€ì¼
        self.styles.add(ParagraphStyle(
            name='Summary',
            parent=self.styles['Normal'],
            fontName=font_name,
            fontSize=11,
            textColor=self.colors['text'],
            spaceAfter=10,
            leading=16,
            leftIndent=15,
            rightIndent=15,
            backColor=colors.Color(0.98, 1.0, 0.98),
            borderPadding=10,
        ))
        
        # í‚¤ì›Œë“œ ìŠ¤íƒ€ì¼
        self.styles.add(ParagraphStyle(
            name='Keywords',
            parent=self.styles['Normal'],
            fontName=font_name,
            fontSize=10,
            textColor=self.colors['accent'],
            spaceAfter=8,
            leftIndent=10,
        ))
    
    def create_header_section(self, keywords, articles_count, user_email):
        """í—¤ë” ì„¹ì…˜ ìƒì„±"""
        elements = []
        
        # ë©”ì¸ ì œëª©
        title = Paragraph("ğŸ“° ëŒ€í•œë¯¼êµ­ ë‰´ìŠ¤ ìë™í™” ë³´ê³ ì„œ", self.styles['MainTitle'])
        elements.append(title)
        elements.append(Spacer(1, 20))
        
        # ë³´ê³ ì„œ ì •ë³´ í…Œì´ë¸”
        report_info = [
            ['ğŸ” ê²€ìƒ‰ í‚¤ì›Œë“œ', ', '.join(keywords)],
            ['ğŸ“Š ìˆ˜ì§‘ëœ ê¸°ì‚¬', f'{articles_count}ê±´'],
            ['ğŸ“… ìƒì„± ì¼ì‹œ', datetime.now().strftime('%Yë…„ %mì›” %dì¼ %Hì‹œ %Më¶„')],
            ['ğŸ‘¤ ìš”ì²­ì', user_email],
            ['ğŸ¢ ì–¸ë¡ ì‚¬', 'ë§¤ì¼ê²½ì œ, ì—°í•©ë‰´ìŠ¤, SBS, JTBC (ì´ 25ê°œ RSS)']
        ]
        
        info_table = Table(report_info, colWidths=[1.5*inch, 4.5*inch])
        info_table.setStyle(TableStyle([
            ('BACKGROUND', (0, 0), (0, -1), self.colors['light_bg']),
            ('BACKGROUND', (1, 0), (1, -1), colors.white),
            ('TEXTCOLOR', (0, 0), (-1, -1), self.colors['text']),
            ('FONTNAME', (0, 0), (0, -1), 'korean-bold'),
            ('FONTNAME', (1, 0), (1, -1), 'korean'),
            ('FONTSIZE', (0, 0), (-1, -1), 10),
            ('ALIGN', (0, 0), (-1, -1), 'LEFT'),
            ('VALIGN', (0, 0), (-1, -1), 'MIDDLE'),
            ('TOPPADDING', (0, 0), (-1, -1), 8),
            ('BOTTOMPADDING', (0, 0), (-1, -1), 8),
            ('LEFTPADDING', (0, 0), (-1, -1), 12),
            ('RIGHTPADDING', (0, 0), (-1, -1), 12),
            ('GRID', (0, 0), (-1, -1), 1, self.colors['border']),
            ('LINEBELOW', (0, 0), (-1, 0), 2, self.colors['primary']),
        ]))
        
        elements.append(info_table)
        elements.append(Spacer(1, 30))
        
        return elements
    
    def create_article_section(self, article, index):
        """ê°œë³„ ê¸°ì‚¬ ì„¹ì…˜ ìƒì„±"""
        elements = []
        
        # ê¸°ì‚¬ ë²ˆí˜¸ì™€ ì œëª©
        title_text = f"{index}. {article['title']}"
        article_title = Paragraph(title_text, self.styles['ArticleTitle'])
        elements.append(article_title)
        elements.append(Spacer(1, 10))
        
        # ê¸°ì‚¬ ë©”íƒ€ ì •ë³´
        meta_data = [
            ['ğŸ”— URL', article['link'][:80] + '...' if len(article['link']) > 80 else article['link']],
            ['ğŸ“… ë°œí–‰ì¼', article.get('published', 'N/A')],
            ['ğŸ“‚ ì¹´í…Œê³ ë¦¬', article.get('category', 'N/A')],
        ]
        
        meta_table = Table(meta_data, colWidths=[1*inch, 5*inch])
        meta_table.setStyle(TableStyle([
            ('BACKGROUND', (0, 0), (0, -1), colors.Color(0.95, 0.95, 0.95)),
            ('BACKGROUND', (1, 0), (1, -1), colors.white),
            ('TEXTCOLOR', (0, 0), (-1, -1), self.colors['text']),
            ('FONTNAME', (0, 0), (0, -1), 'korean-bold'),
            ('FONTNAME', (1, 0), (1, -1), 'korean'),
            ('FONTSIZE', (0, 0), (-1, -1), 9),
            ('ALIGN', (0, 0), (-1, -1), 'LEFT'),
            ('VALIGN', (0, 0), (-1, -1), 'TOP'),
            ('TOPPADDING', (0, 0), (-1, -1), 6),
            ('BOTTOMPADDING', (0, 0), (-1, -1), 6),
            ('LEFTPADDING', (0, 0), (-1, -1), 8),
            ('RIGHTPADDING', (0, 0), (-1, -1), 8),
            ('GRID', (0, 0), (-1, -1), 0.5, self.colors['border']),
        ]))
        
        elements.append(meta_table)
        elements.append(Spacer(1, 10))
        
        # í‚¤ì›Œë“œ ì„¹ì…˜
        if article.get('keywords'):
            keywords_text = f"ğŸ·ï¸ ì£¼ìš” í‚¤ì›Œë“œ: {', '.join(article['keywords'][:8])}"
            keywords_para = Paragraph(keywords_text, self.styles['Keywords'])
            elements.append(keywords_para)
            elements.append(Spacer(1, 8))
        
        # ìš”ì•½ ì„¹ì…˜
        summary_text = article.get('summary', 'ìš”ì•½ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.')
        if 'ìš”ì•½ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤' in summary_text or 'ì˜¤ë¥˜' in summary_text:
            summary_formatted = f"âš ï¸ {summary_text}"
        else:
            summary_formatted = f"ğŸ“ {summary_text}"
        
        summary_para = Paragraph(summary_formatted, self.styles['Summary'])
        elements.append(summary_para)
        elements.append(Spacer(1, 20))
        
        # êµ¬ë¶„ì„ 
        if index < len(self.articles_data):  # ë§ˆì§€ë§‰ ê¸°ì‚¬ê°€ ì•„ë‹Œ ê²½ìš°
            line_data = [[''] * 6]
            line_table = Table(line_data, colWidths=[6*inch])
            line_table.setStyle(TableStyle([
                ('LINEABOVE', (0, 0), (-1, -1), 1, self.colors['border']),
            ]))
            elements.append(line_table)
            elements.append(Spacer(1, 15))
        
        return elements
    
    def create_footer_section(self):
        """í‘¸í„° ì„¹ì…˜ ìƒì„±"""
        elements = []
        
        elements.append(Spacer(1, 30))
        
        footer_data = [
            ['ìƒì„± ì‹œìŠ¤í…œ: AI ë‰´ìŠ¤ ìë™í™” ì‹œìŠ¤í…œ v2.0', f'ìƒì„± ì‹œê°„: {datetime.now().strftime("%Y-%m-%d %H:%M:%S")}']
        ]
        
        footer_table = Table(footer_data, colWidths=[3*inch, 3*inch])
        footer_table.setStyle(TableStyle([
            ('BACKGROUND', (0, 0), (-1, -1), colors.Color(0.95, 0.95, 0.95)),
            ('TEXTCOLOR', (0, 0), (-1, -1), colors.Color(0.5, 0.5, 0.5)),
            ('FONTNAME', (0, 0), (-1, -1), 'korean'),
            ('FONTSIZE', (0, 0), (-1, -1), 8),
            ('ALIGN', (0, 0), (0, -1), 'LEFT'),
            ('ALIGN', (1, 0), (1, -1), 'RIGHT'),
            ('VALIGN', (0, 0), (-1, -1), 'MIDDLE'),
            ('TOPPADDING', (0, 0), (-1, -1), 6),
            ('BOTTOMPADDING', (0, 0), (-1, -1), 6),
            ('LEFTPADDING', (0, 0), (-1, -1), 10),
            ('RIGHTPADDING', (0, 0), (-1, -1), 10),
        ]))
        
        elements.append(footer_table)
        
        return elements
    
    def generate_report(self, articles_data, keywords, user_email):
        """ì‚¬ìš©ì ì¹œí™”ì ì¸ PDF ë³´ê³ ì„œ ìƒì„±"""
        self.articles_data = articles_data  # í´ë˜ìŠ¤ ë³€ìˆ˜ë¡œ ì €ì¥
        
        buffer = io.BytesIO()
        doc = SimpleDocTemplate(
            buffer,
            pagesize=A4,
            rightMargin=50,
            leftMargin=50,
            topMargin=50,
            bottomMargin=50
        )
        
        story = []
        
        # 1. í—¤ë” ì„¹ì…˜
        header_elements = self.create_header_section(keywords, len(articles_data), user_email)
        story.extend(header_elements)
        
        # 2. ê¸°ì‚¬ ëª©ë¡ ì„¹ì…˜ ì œëª©
        section_title = Paragraph("ğŸ“„ ìˆ˜ì§‘ëœ ë‰´ìŠ¤ ê¸°ì‚¬ ëª©ë¡", self.styles['SectionTitle'])
        story.append(section_title)
        story.append(Spacer(1, 15))
        
        # 3. ê° ê¸°ì‚¬ ì„¹ì…˜
        for i, article in enumerate(articles_data, 1):
            article_elements = self.create_article_section(article, i)
            story.extend(article_elements)
            
            # í˜ì´ì§€ ë‚˜ëˆ„ê¸° (4ê°œ ê¸°ì‚¬ë§ˆë‹¤)
            if i % 4 == 0 and i < len(articles_data):
                story.append(Spacer(1, 30))
        
        # 4. í‘¸í„° ì„¹ì…˜
        footer_elements = self.create_footer_section()
        story.extend(footer_elements)
        
        # PDF ìƒì„±
        doc.build(story)
        buffer.seek(0)
        return buffer

class EmailSender:
    """ì´ë©”ì¼ ë°œì†¡ í´ë˜ìŠ¤"""
    
    def __init__(self):
        self.smtp_server = os.getenv('SMTP_SERVER', 'smtp.gmail.com')
        self.smtp_port = int(os.getenv('SMTP_PORT', 587))
        self.sender_email = os.getenv('GMAIL_EMAIL')
        self.sender_password = os.getenv('GMAIL_APP_PASSWORD')
    
    def is_configured(self):
        """ì´ë©”ì¼ ì„¤ì •ì´ ì™„ë£Œë˜ì—ˆëŠ”ì§€ í™•ì¸"""
        return bool(self.sender_email and self.sender_password)
    
    def send_report_email(self, recipient_email, pdf_buffer, keywords, sender_email=None, sender_password=None):
        """PDF ë³´ê³ ì„œë¥¼ ì´ë©”ì¼ë¡œ ë°œì†¡"""
        try:
            email = sender_email or self.sender_email
            password = sender_password or self.sender_password
            
            if not email or not password:
                return False, "ì´ë©”ì¼ ì„¤ì •ì´ ì™„ë£Œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
            
            # ì´ë©”ì¼ ë©”ì‹œì§€ ìƒì„±
            msg = MIMEMultipart()
            msg['From'] = email
            msg['To'] = recipient_email
            msg['Subject'] = f"ë‰´ìŠ¤ ìš”ì•½ ë³´ê³ ì„œ - {', '.join(keywords)} ({datetime.now().strftime('%Y-%m-%d')})"
            
            # ì´ë©”ì¼ ë³¸ë¬¸
            body = f"""ì•ˆë…•í•˜ì„¸ìš”,

ìš”ì²­í•˜ì‹  ë‰´ìŠ¤ ìš”ì•½ ë³´ê³ ì„œë¥¼ ì²¨ë¶€íŒŒì¼ë¡œ ë³´ë‚´ë“œë¦½ë‹ˆë‹¤.

[ë³´ê³ ì„œ ì •ë³´]
- ê²€ìƒ‰ í‚¤ì›Œë“œ: {', '.join(keywords)}
- ìƒì„± ì¼ì‹œ: {datetime.now().strftime('%Yë…„ %mì›” %dì¼ %Hì‹œ %Më¶„')}
- ë°œì†¡ì: {email}

ì²¨ë¶€íŒŒì¼ì„ í™•ì¸í•´ì£¼ì„¸ìš”.

ê°ì‚¬í•©ë‹ˆë‹¤.

---
ë‰´ìŠ¤ ìë™í™” ì‹œìŠ¤í…œ"""
            
            msg.attach(MIMEText(body, 'plain', 'utf-8'))
            
            # PDF ì²¨ë¶€íŒŒì¼ ì¶”ê°€
            attachment = MIMEBase('application', 'octet-stream')
            attachment.set_payload(pdf_buffer.read())
            encoders.encode_base64(attachment)
            
            filename = f"news_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.pdf"
            attachment.add_header(
                'Content-Disposition',
                f'attachment; filename={filename}'
            )
            msg.attach(attachment)
            
            # SMTP ì„œë²„ ì—°ê²° ë° ë°œì†¡
            server = smtplib.SMTP(self.smtp_server, self.smtp_port)
            server.starttls()
            server.login(email, password)
            text = msg.as_string()
            server.sendmail(email, recipient_email, text)
            server.quit()
            
            return True, f"ì´ë©”ì¼ì´ ì„±ê³µì ìœ¼ë¡œ ë°œì†¡ë˜ì—ˆìŠµë‹ˆë‹¤! ({email} -> {recipient_email})"
            
        except Exception as e:
            return False, f"ì´ë©”ì¼ ë°œì†¡ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"

def main():
    """ë©”ì¸ Streamlit ì•±"""
    st.set_page_config(
        page_title="ë‰´ìŠ¤ ìë™í™” ì‹œìŠ¤í…œ",
        page_icon="ğŸ“°",
        layout="wide",
        initial_sidebar_state="expanded"
    )
    
    # ì»¤ìŠ¤í…€ CSS ì¶”ê°€ (UI ê°œì„ )
    st.markdown("""
    <style>
    /* í…ìŠ¤íŠ¸ ì…ë ¥ì°½ ìŠ¤íƒ€ì¼ ê°œì„  */
    .stTextInput > div > div > input {
        height: 3rem !important;
        padding: 0.75rem 1rem !important;
        display: flex !important;
        align-items: center !important;
        vertical-align: middle !important;
        line-height: 1.5rem !important;
        font-size: 1rem !important;
    }
    
    /* í…ìŠ¤íŠ¸ ì…ë ¥ì°½ ë¼ë²¨ ìŠ¤íƒ€ì¼ */
    .stTextInput > label {
        font-size: 1rem !important;
        font-weight: 600 !important;
        margin-bottom: 0.5rem !important;
    }
    
    /* ë²„íŠ¼ ìŠ¤íƒ€ì¼ ê°œì„  */
    .stButton > button {
        height: 3rem !important;
        padding: 0.75rem 1rem !important;
        display: flex !important;
        align-items: center !important;
        justify-content: center !important;
        font-size: 1rem !important;
        font-weight: 600 !important;
        border-radius: 0.5rem !important;
        margin-top: 0rem !important;
    }
    
    /* ë²„íŠ¼ ì»¨í…Œì´ë„ˆ ì •ë ¬ */
    .stButton {
        display: flex !important;
        align-items: flex-end !important;
        height: 100% !important;
    }
    
    /* ì»¬ëŸ¼ ë†’ì´ í†µì¼ */
    .stColumn {
        display: flex !important;
        flex-direction: column !important;
    }
    
    /* ì»¬ëŸ¼ ê°„ê²© ì¡°ì • */
    .block-container {
        padding-top: 1rem;
    }
    
    /* ë©”íŠ¸ë¦­ ì¹´ë“œ ìŠ¤íƒ€ì¼ ê°œì„  */
    .metric-container {
        background: linear-gradient(90deg, #667eea 0%, #764ba2 100%);
        padding: 1rem;
        border-radius: 10px;
        color: white;
    }
    
    /* í—¤ë” ìŠ¤íƒ€ì¼ ê°œì„  */
    .main-header {
        background: linear-gradient(90deg, #667eea 0%, #764ba2 100%);
        padding: 2rem;
        border-radius: 10px;
        color: white;
        text-align: center;
        margin-bottom: 2rem;
    }
    
    /* ì…ë ¥ì°½ê³¼ ë²„íŠ¼ì˜ ìˆ˜ì§ ì •ë ¬ì„ ìœ„í•œ ì¶”ê°€ ìŠ¤íƒ€ì¼ */
    .stTextInput {
        margin-bottom: 0 !important;
    }
    
    /* ë¼ë²¨ê³¼ ì…ë ¥ì°½ ì‚¬ì´ ê°„ê²© ì¡°ì • */
    .stTextInput > div {
        gap: 0.5rem !important;
    }
    
    /* Primary ë²„íŠ¼ ìŠ¤íƒ€ì¼ ê°•í™” */
    .stButton > button[kind="primary"] {
        background: linear-gradient(90deg, #ff6b6b 0%, #ee5a52 100%) !important;
        border: none !important;
        color: white !important;
        box-shadow: 0 2px 4px rgba(0,0,0,0.1) !important;
    }
    
    .stButton > button[kind="primary"]:hover {
        background: linear-gradient(90deg, #ff5252 0%, #d32f2f 100%) !important;
        box-shadow: 0 4px 8px rgba(0,0,0,0.2) !important;
        transform: translateY(-1px) !important;
    }
    </style>
    """, unsafe_allow_html=True)
    
    # í—¤ë” (ìŠ¤íƒ€ì¼ ê°œì„ )
    st.markdown("""
    <div class="main-header">
        <h1 style="margin:0;">ğŸ“° ëŒ€í•œë¯¼êµ­ ë‰´ìŠ¤ ìë™í™” ì‹œìŠ¤í…œ</h1>
        <p style="margin:0.5rem 0 0 0; opacity:0.9;">êµ­ë‚´ ëŒ€í‘œ ì–¸ë¡ ì‚¬ë“¤ì„ í•œë²ˆì— ë³´ì‹¤ ìˆ˜ ìˆëŠ” ìŠ¤ë§ˆíŠ¸í•œ ë‰´ìŠ¤ ìˆ˜ì§‘ í”Œë«í¼ì…ë‹ˆë‹¤ - ìš”ì•½ ë° PDF ë³´ê³ ì„œ ìƒì„±</p>
    </div>
    """, unsafe_allow_html=True)
    
    # ì‚¬ì´ë“œë°” ì„¤ì • (RSS ì„ íƒ ê¸°ëŠ¥ ì œê±°)
    st.sidebar.header("âš™ï¸ ì‹œìŠ¤í…œ ì„¤ì •")
    
    # ê³ ê¸‰ ì„¤ì •ë§Œ ìœ ì§€
    with st.sidebar.expander("ğŸ”§ ê³ ê¸‰ ì„¤ì •", expanded=False):
        summary_sentences = st.slider("ğŸ“ ìš”ì•½ ë¬¸ì¥ ìˆ˜", 1, 5, 3)
        keyword_count = st.slider("ğŸ·ï¸ í‚¤ì›Œë“œ ì¶”ì¶œ ìˆ˜", 3, 15, 8)
        
        st.write("**ğŸ¯ ìš”ì•½ ë°©ì‹:**")
        summary_method = st.radio(
            "ë°©ì‹ ì„ íƒ",
            ["í•œêµ­ì–´ ìµœì í™”", "Sumy ë¼ì´ë¸ŒëŸ¬ë¦¬", "ê°„ë‹¨ ìš”ì•½"],
            index=0,
            help="í•œêµ­ì–´ ìµœì í™”: í•œêµ­ì–´ ë‰´ìŠ¤ì— íŠ¹í™”ëœ ìš”ì•½ ë°©ì‹"
        )
    
    # ì´ë©”ì¼ ì„¤ì • ìƒíƒœ í‘œì‹œ
    email_sender = EmailSender()
    if email_sender.is_configured():
        st.sidebar.success("âœ… ì´ë©”ì¼ ì„¤ì • ì™„ë£Œ")
        st.sidebar.info(f"ğŸ“§ ë°œì†¡ì: {email_sender.sender_email}")
    else:
        st.sidebar.warning("âš ï¸ ì´ë©”ì¼ ì„¤ì • í•„ìš”")
    
    # ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
    if 'articles_data' not in st.session_state:
        st.session_state.articles_data = []
    if 'processing_complete' not in st.session_state:
        st.session_state.processing_complete = False
    
    # 1ë‹¨ê³„: í‚¤ì›Œë“œ ì…ë ¥
    st.header("1ï¸âƒ£ í‚¤ì›Œë“œ ì…ë ¥ ë° ë‰´ìŠ¤ ìˆ˜ì§‘")
    
    col1, col2 = st.columns([4, 1])
    
    with col1:
        keywords_input = st.text_input(
            "ğŸ” ê²€ìƒ‰í•  í‚¤ì›Œë“œë¥¼ ì…ë ¥í•˜ì„¸ìš” (ì‰¼í‘œë¡œ êµ¬ë¶„)",
            placeholder="ì˜ˆ: AI, ì¸ê³µì§€ëŠ¥, ë¨¸ì‹ ëŸ¬ë‹, ë”¥ëŸ¬ë‹",
            help="ì—¬ëŸ¬ í‚¤ì›Œë“œëŠ” ì‰¼í‘œ(,)ë¡œ êµ¬ë¶„í•´ì„œ ì…ë ¥í•˜ì„¸ìš”."
        )
    
    with col2:
        # ë¼ë²¨ ë†’ì´ì™€ ë™ì¼í•œ ê³µê°„ í™•ë³´
        st.markdown('<div style="height: 1.5rem; margin-bottom: 0.5rem;"></div>', unsafe_allow_html=True)
        search_button = st.button("ğŸš€ ë‰´ìŠ¤ ìˆ˜ì§‘ ì‹œì‘", type="primary", use_container_width=True)
    
    # SBS í—¤ë“œë¼ì¸ ë‰´ìŠ¤ ë¯¸ë¦¬ë³´ê¸° (ì²« í™”ë©´ í™œì„±í™”)
    if not st.session_state.processing_complete:
        st.markdown("---")
        st.subheader("ğŸ“º SBS í—¤ë“œë¼ì¸ ë‰´ìŠ¤ (ì‹¤ì‹œê°„)")
        
        # SBS í—¤ë“œë¼ì¸ ë‰´ìŠ¤ ê°€ì ¸ì˜¤ê¸°
        @st.cache_data(ttl=300)  # 5ë¶„ ìºì‹œ
        def get_sbs_headlines():
            try:
                collector = NewsCollector()
                sbs_url = "https://news.sbs.co.kr/news/headlineRssFeed.do?plink=RSSREADER"
                articles = collector.get_rss_feeds(sbs_url, "SBS_í—¤ë“œë¼ì¸")
                return articles[:10]  # ìƒìœ„ 10ê°œë§Œ
            except Exception as e:
                st.error(f"SBS ë‰´ìŠ¤ ë¡œë”© ì¤‘ ì˜¤ë¥˜: {str(e)}")
                return []
        
        sbs_headlines = get_sbs_headlines()
        
        if sbs_headlines:
            # ë‰´ìŠ¤ ì¹´ë“œ ìŠ¤íƒ€ì¼ë¡œ í‘œì‹œ
            for i, article in enumerate(sbs_headlines, 1):
                with st.container():
                    col1, col2 = st.columns([1, 20])
                    
                    with col1:
                        st.markdown(f"**{i}**")
                    
                    with col2:
                        # ì œëª©ì„ í´ë¦­ ê°€ëŠ¥í•œ ë§í¬ë¡œ í‘œì‹œ
                        st.markdown(f"**[{article['title']}]({article['link']})**")
                        
                        # ë°œí–‰ì¼ê³¼ ê°„ë‹¨í•œ ì„¤ëª…
                        if article.get('published'):
                            st.caption(f"ğŸ“… {article['published']}")
                        
                        if article.get('description'):
                            # ì„¤ëª…ì´ ë„ˆë¬´ ê¸¸ë©´ ìë¥´ê¸°
                            desc = article['description'][:150] + "..." if len(article['description']) > 150 else article['description']
                            st.markdown(f"<small style='color: #666;'>{desc}</small>", unsafe_allow_html=True)
                        
                        st.markdown("---")
        else:
            st.info("SBS í—¤ë“œë¼ì¸ ë‰´ìŠ¤ë¥¼ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘ì…ë‹ˆë‹¤...")
        
        st.markdown("ğŸ’¡ **ìœ„ ë‰´ìŠ¤ë“¤ì€ ì‹¤ì‹œê°„ SBS í—¤ë“œë¼ì¸ì…ë‹ˆë‹¤. í‚¤ì›Œë“œë¥¼ ì…ë ¥í•˜ì—¬ ë§ì¶¤í˜• ë‰´ìŠ¤ ê²€ìƒ‰ì„ ì‹œì‘í•´ë³´ì„¸ìš”!**")
    
    # ë‰´ìŠ¤ ìˆ˜ì§‘ ì‹¤í–‰
    if search_button and keywords_input:
        keywords = [kw.strip() for kw in keywords_input.split(',') if kw.strip()]
        
        if keywords:
            # ê°„ë‹¨í•œ ë¡œë”© ë©”ì‹œì§€ë§Œ í‘œì‹œ
            with st.spinner("ğŸ”„ ë‰´ìŠ¤ ê¸°ì‚¬ë¥¼ ìˆ˜ì§‘í•˜ê³  ë¶„ì„í•˜ê³  ìˆìŠµë‹ˆë‹¤..."):
                try:
                    collector = NewsCollector()
                    
                    # ëª¨ë“  RSS ìë™ ìˆ˜ì§‘ (ìƒì„¸ ì§„í–‰ë¥  ì—†ì´)
                    articles = collector.collect_news_with_content(keywords)
                    
                    if articles:
                        processor = TextProcessor()
                        processed_articles = []
                        
                        # AI ë¶„ì„ ì§„í–‰ë¥  (ê°„ë‹¨í•˜ê²Œ)
                        progress_bar = st.progress(0)
                        status_text = st.empty()
                        status_text.text(f"AI ë¶„ì„ ì¤‘... (0/{len(articles)})")
                        
                        for i, article in enumerate(articles):
                            progress_bar.progress((i + 1) / len(articles))
                            status_text.text(f"AI ë¶„ì„ ì¤‘... ({i+1}/{len(articles)})")
                            
                            # ìš”ì•½ ë°©ì‹ ì„ íƒì— ë”°ë¥¸ ì²˜ë¦¬
                            if summary_method == "í•œêµ­ì–´ ìµœì í™”":
                                summary = processor.simple_summarize(article['content'], summary_sentences)
                            else:
                                summary = processor.summarize_text(article['content'], summary_sentences)
                            
                            extracted_keywords = processor.extract_keywords(article['content'], keyword_count)
                            
                            article['summary'] = summary
                            article['keywords'] = extracted_keywords
                            processed_articles.append(article)
                        
                        # ì§„í–‰ë¥  ë°” ì œê±°
                        progress_bar.empty()
                        status_text.empty()
                        
                        st.session_state.articles_data = processed_articles
                        st.session_state.processing_complete = True
                        st.session_state.search_keywords = keywords
                        
                        st.balloons()
                        
                        # ìµœì¢… ê²°ê³¼ë§Œ ê°„ë‹¨íˆ í‘œì‹œ
                        category_summary = {}
                        for article in processed_articles:
                            cat = article.get('category', 'ê¸°íƒ€')
                            category_summary[cat] = category_summary.get(cat, 0) + 1
                        
                        st.success(f"ğŸ‰ ìˆ˜ì§‘ ì™„ë£Œ! {len(processed_articles)}ê°œì˜ ê¸°ì‚¬ë¥¼ ì„±ê³µì ìœ¼ë¡œ ìˆ˜ì§‘í•˜ê³  ë¶„ì„í–ˆìŠµë‹ˆë‹¤!")
                        
                        # ì¹´í…Œê³ ë¦¬ë³„ ê°„ë‹¨í•œ í†µê³„ (í•œ ì¤„ë¡œ)
                        category_text = ", ".join([f"{cat}({count})" for cat, count in category_summary.items()])
                        st.info(f"ğŸ“Š ì¹´í…Œê³ ë¦¬ë³„ ìˆ˜ì§‘: {category_text}")
                        
                    else:
                        st.warning("ğŸ˜… í•´ë‹¹ í‚¤ì›Œë“œë¡œ ê²€ìƒ‰ëœ ê¸°ì‚¬ê°€ ì—†ìŠµë‹ˆë‹¤.")
                        
                except Exception as e:
                    st.error(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        else:
            st.warning("âš ï¸ í‚¤ì›Œë“œë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
    
    # 2ë‹¨ê³„: ê²°ê³¼ í‘œì‹œ
    if st.session_state.processing_complete and st.session_state.articles_data:
        st.header("2ï¸âƒ£ ìˆ˜ì§‘ ê²°ê³¼ ë¶„ì„")
        
        # í†µê³„ ì •ë³´ í‘œì‹œ
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            st.metric("ğŸ“° ìˆ˜ì§‘ëœ ê¸°ì‚¬", len(st.session_state.articles_data))
        
        with col2:
            successful_summaries = sum(1 for article in st.session_state.articles_data 
                                     if 'ìš”ì•½ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤' not in article.get('summary', ''))
            success_rate = (successful_summaries / len(st.session_state.articles_data)) * 100
            st.metric("âœ… ìš”ì•½ ì„±ê³µë¥ ", f"{success_rate:.1f}%")
        
        with col3:
            avg_keywords = sum(len(article.get('keywords', [])) for article in st.session_state.articles_data) / len(st.session_state.articles_data)
            st.metric("ğŸ·ï¸ í‰ê·  í‚¤ì›Œë“œ", f"{avg_keywords:.1f}ê°œ")
        
        with col4:
            st.metric("ğŸ” ê²€ìƒ‰ í‚¤ì›Œë“œ", len(st.session_state.search_keywords))
        
        # í‚¤ì›Œë“œ í´ë¼ìš°ë“œ
        with st.expander("ğŸ·ï¸ ì£¼ìš” í‚¤ì›Œë“œ ë¶„ì„", expanded=False):
            all_keywords = []
            for article in st.session_state.articles_data:
                all_keywords.extend(article.get('keywords', []))
            
            if all_keywords:
                keyword_freq = Counter(all_keywords)
                top_keywords = keyword_freq.most_common(15)
                
                keyword_html = ""
                colors_list = ['#FF6B6B', '#4ECDC4', '#45B7D1', '#96CEB4', '#FCEA2B', '#FF9F43', '#EE5A52', '#0FB9B1', '#A29BFE', '#FD79A8']
                
                for i, (keyword, freq) in enumerate(top_keywords):
                    color = colors_list[i % len(colors_list)]
                    keyword_html += f'<span style="background-color: {color}; color: white; padding: 5px 10px; margin: 3px; border-radius: 15px; font-size: 12px; display: inline-block;">{keyword} ({freq})</span>'
                
                st.markdown(keyword_html, unsafe_allow_html=True)
            else:
                st.info("í‚¤ì›Œë“œê°€ ì¶”ì¶œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        
        # ê¸°ì‚¬ ëª©ë¡ í‘œì‹œ
        st.subheader("ğŸ“„ ìˆ˜ì§‘ëœ ê¸°ì‚¬ ëª©ë¡")
        
        # ì¹´í…Œê³ ë¦¬ë³„ í•„í„°ë§ ì˜µì…˜ë§Œ ìœ ì§€ (ë±ƒì§€ í‘œì‹œ ì˜µì…˜ ì œê±°)
        if st.session_state.articles_data:
            categories_in_results = list(set(article.get('category', 'ê¸°íƒ€') for article in st.session_state.articles_data))
            
            selected_filter_category = st.selectbox(
                "ì¹´í…Œê³ ë¦¬ë³„ í•„í„°ë§",
                options=["ì „ì²´ ë³´ê¸°"] + categories_in_results,
                index=0
            )
        
        # í•„í„°ë§ëœ ê¸°ì‚¬ ëª©ë¡
        filtered_display_articles = st.session_state.articles_data
        if selected_filter_category != "ì „ì²´ ë³´ê¸°":
            filtered_display_articles = [
                article for article in st.session_state.articles_data 
                if article.get('category', 'ê¸°íƒ€') == selected_filter_category
            ]
        
        # ê¸°ì‚¬ ëª©ë¡ í‘œì‹œ (ë±ƒì§€ ì—†ì´ ê¹”ë”í•˜ê²Œ)
        for i, article in enumerate(filtered_display_articles, 1):
            with st.expander(f"ğŸ“° {i}. {article['title']}", expanded=False):
                col1, col2 = st.columns([3, 1])
                
                with col1:
                    st.markdown(f"**ğŸ”— ë§í¬:** {article['link']}")
                    st.markdown(f"**ğŸ“… ë°œí–‰ì¼:** {article.get('published', 'N/A')}")
                    st.markdown(f"**ğŸ“‚ ì¹´í…Œê³ ë¦¬:** {article.get('category', 'ê¸°íƒ€')}")
                    
                    # ìš”ì•½ í’ˆì§ˆì— ë”°ë¥¸ ìƒ‰ìƒ í‘œì‹œ
                    summary = article['summary']
                    if 'ìš”ì•½ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤' in summary or 'ì˜¤ë¥˜' in summary:
                        st.markdown(f"**ğŸ“ ìš”ì•½:** <span style='color: orange;'>{summary}</span>", unsafe_allow_html=True)
                    else:
                        st.markdown(f"**ğŸ“ ìš”ì•½:** <span style='color: green;'>{summary}</span>", unsafe_allow_html=True)
                
                with col2:
                    st.markdown("**ğŸ·ï¸ í‚¤ì›Œë“œ:**")
                    for keyword in article['keywords'][:6]:
                        st.markdown(f"â€¢ {keyword}")
        
        # 3ë‹¨ê³„: PDF ìƒì„± ë° ì´ë©”ì¼ ë°œì†¡
        st.header("3ï¸âƒ£ ë³´ê³ ì„œ ìƒì„± ë° ë°œì†¡")
        
        # ë ˆì´ì•„ì›ƒ ê°œì„ : ì´ë©”ì¼ ì…ë ¥ê³¼ ë²„íŠ¼ì„ ê°™ì€ í–‰ì— ë°°ì¹˜
        col1, col2, col3 = st.columns([2, 3, 2])
        
        with col1:
            # CSV ë‹¤ìš´ë¡œë“œ
            if st.button("ğŸ“Š CSV ë‹¤ìš´ë¡œë“œ", use_container_width=True):
                try:
                    df_data = []
                    for i, article in enumerate(st.session_state.articles_data, 1):
                        df_data.append({
                            'ë²ˆí˜¸': i,
                            'ì œëª©': article['title'],
                            'URL': article['link'],
                            'ë°œí–‰ì¼': article.get('published', ''),
                            'ì¹´í…Œê³ ë¦¬': article.get('category', ''),
                            'ìš”ì•½': article.get('summary', ''),
                            'í‚¤ì›Œë“œ': ', '.join(article.get('keywords', [])),
                            'ìˆ˜ì§‘ì‹œê°„': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
                        })
                    
                    df = pd.DataFrame(df_data)
                    csv = df.to_csv(index=False, encoding='utf-8-sig')
                    
                    st.download_button(
                        label="ğŸ’¾ CSV íŒŒì¼ ë‹¤ìš´ë¡œë“œ",
                        data=csv,
                        file_name=f"news_data_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
                        mime="text/csv"
                    )
                    st.success("âœ… CSV íŒŒì¼ì´ ì¤€ë¹„ë˜ì—ˆìŠµë‹ˆë‹¤!")
                    
                except Exception as e:
                    st.error(f"âŒ CSV ìƒì„± ì˜¤ë¥˜: {str(e)}")
        
        with col2:
            recipient_email = st.text_input(
                "ğŸ“§ ë°›ì„ ì´ë©”ì¼ ì£¼ì†Œ",
                placeholder="example@gmail.com",
                help="PDF ë³´ê³ ì„œë¥¼ ë°›ì„ ì´ë©”ì¼ ì£¼ì†Œë¥¼ ì…ë ¥í•˜ì„¸ìš”"
            )
        
        with col3:
            # ë¼ë²¨ ë†’ì´ì™€ ë™ì¼í•œ ê³µê°„ í™•ë³´
            st.markdown('<div style="height: 1.5rem; margin-bottom: 0.5rem;"></div>', unsafe_allow_html=True)
            generate_pdf_button = st.button("ğŸ“„ PDF ìƒì„± ë° ë°œì†¡", type="primary", use_container_width=True)
        
        # ì´ë©”ì¼ ì„¤ì •
        email_sender = EmailSender()
        manual_email_input = not email_sender.is_configured()
        
        with st.expander("ğŸ“§ ì´ë©”ì¼ ë°œì†¡ ì„¤ì •", expanded=manual_email_input):
            if email_sender.is_configured():
                st.success(f"âœ… í˜„ì¬ ì„¤ì •: {email_sender.sender_email}")
                use_env_email = st.checkbox("í™˜ê²½ë³€ìˆ˜ ì„¤ì • ì‚¬ìš©", value=True)
            else:
                use_env_email = False
                st.warning("í™˜ê²½ë³€ìˆ˜ì—ì„œ ì´ë©”ì¼ ì„¤ì •ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            
            if not use_env_email or not email_sender.is_configured():
                st.markdown("**ğŸ“¤ ìˆ˜ë™ ì´ë©”ì¼ ì„¤ì •:**")
                manual_sender_email = st.text_input(
                    "ë°œì†¡ì Gmail ì£¼ì†Œ", 
                    value=email_sender.sender_email or "",
                    placeholder="your_email@gmail.com"
                )
                manual_sender_password = st.text_input(
                    "Gmail ì•± ë¹„ë°€ë²ˆí˜¸", 
                    type="password",
                    help="Gmail 2ë‹¨ê³„ ì¸ì¦ í›„ ìƒì„±í•œ ì•± ë¹„ë°€ë²ˆí˜¸ë¥¼ ì…ë ¥í•˜ì„¸ìš”"
                )
            else:
                manual_sender_email = None
                manual_sender_password = None
        
        # PDF ìƒì„± ë° ë°œì†¡
        if generate_pdf_button and recipient_email:
            try:
                with st.spinner("ğŸ“„ PDF ë³´ê³ ì„œë¥¼ ìƒì„±í•˜ê³  ìˆìŠµë‹ˆë‹¤..."):
                    pdf_generator = PDFGenerator()
                    pdf_buffer = pdf_generator.generate_report(
                        st.session_state.articles_data,
                        st.session_state.search_keywords,
                        recipient_email
                    )
                    
                    pdf_filename = f"news_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.pdf"
                    
                    col1, col2 = st.columns(2)
                    with col1:
                        st.download_button(
                            label="ğŸ“„ PDF ë‹¤ìš´ë¡œë“œ",
                            data=pdf_buffer.getvalue(),
                            file_name=pdf_filename,
                            mime="application/pdf",
                            use_container_width=True
                        )
                    
                    with col2:
                        st.success("âœ… PDF ìƒì„± ì™„ë£Œ!")
                    
                    # ì´ë©”ì¼ ë°œì†¡
                    with st.spinner("ğŸ“§ ì´ë©”ì¼ì„ ë°œì†¡í•˜ê³  ìˆìŠµë‹ˆë‹¤..."):
                        pdf_buffer.seek(0)
                        
                        success, message = email_sender.send_report_email(
                            recipient_email,
                            pdf_buffer,
                            st.session_state.search_keywords,
                            manual_sender_email,
                            manual_sender_password
                        )
                        
                        if success:
                            st.success(f"ğŸ‰ {message}")
                            st.balloons()
                        else:
                            st.error(f"âŒ {message}")
                    
            except Exception as e:
                st.error(f"âŒ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
        
        elif generate_pdf_button and not recipient_email:
            st.warning("âš ï¸ ë°›ì„ ì´ë©”ì¼ ì£¼ì†Œë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
    
    # ì‚¬ì´ë“œë°” ì¶”ê°€ ì •ë³´
    st.sidebar.markdown("---")
    st.sidebar.header("ğŸ“Š ìˆ˜ì§‘ í†µê³„")
    
    if st.session_state.processing_complete:
        st.sidebar.metric("ìˆ˜ì§‘ëœ ê¸°ì‚¬", len(st.session_state.articles_data))
        st.sidebar.metric("ê²€ìƒ‰ í‚¤ì›Œë“œ", len(st.session_state.get('search_keywords', [])))
        st.sidebar.metric("RSS í”¼ë“œ ìˆ˜", "25ê°œ (ë§¤ê²½+ì—°í•©+SBS+JTBC)")
        
        # ì¹´í…Œê³ ë¦¬ë³„ í†µê³„
        if 'articles_data' in st.session_state and st.session_state.articles_data:
            st.sidebar.write("**ì–¸ë¡ ì‚¬ë³„ ê¸°ì‚¬ ìˆ˜:**")
            media_counts = {}
            for article in st.session_state.articles_data:
                cat = article.get('category', 'ê¸°íƒ€')
                # ì–¸ë¡ ì‚¬ë³„ë¡œ ê·¸ë£¹í™”
                if 'ë§¤ê²½_' in cat:
                    media = 'ë§¤ì¼ê²½ì œ'
                elif 'ì—°í•©' in cat:
                    media = 'ì—°í•©ë‰´ìŠ¤'
                elif 'SBS' in cat:
                    media = 'SBS'
                elif 'JTBC' in cat:
                    media = 'JTBC'
                else:
                    media = 'ê¸°íƒ€'
                
                media_counts[media] = media_counts.get(media, 0) + 1
            
            for media, count in sorted(media_counts.items()):
                st.sidebar.write(f"â€¢ {media}: {count}ê°œ")

if __name__ == "__main__":
    main()